
---------------------------------------
l1 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     40648
           1       1.00      1.00      1.00      2664

    accuracy                           1.00     43312
   macro avg       1.00      1.00      1.00     43312
weighted avg       1.00      1.00      1.00     43312


Confusion_Matrix
[[40648     0]
 [    0  2664]]

Macro f1 1.0

Micro f1 1.0

Weigted f1 1.0

ROC_acc 1.0
---------------------------------------
l1 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.94      1.00      0.97     10163
           1       0.00      0.00      0.00       666

    accuracy                           0.94     10829
   macro avg       0.47      0.50      0.48     10829
weighted avg       0.88      0.94      0.91     10829


Confusion_Matrix
[[10163     0]
 [  666     0]]

Macro f1 0.48413681402439024

Micro f1 0.9384984763136024

Weigted f1 0.9087233245784243

ROC_acc 0.5
---------------------------------------
l1 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     12704
           1       1.00      1.00      1.00       832

    accuracy                           1.00     13536
   macro avg       1.00      1.00      1.00     13536
weighted avg       1.00      1.00      1.00     13536


Confusion_Matrix
[[12704     0]
 [    0   832]]

Macro f1 1.0

Micro f1 1.0

Weigted f1 1.0

ROC_acc 1.0
---------------------------------------
l2 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.92      0.90      0.91     30476
           1       0.78      0.81      0.80     12836

    accuracy                           0.88     43312
   macro avg       0.85      0.86      0.85     43312
weighted avg       0.88      0.88      0.88     43312


Confusion_Matrix
[[27571  2905]
 [ 2424 10412]]

Macro f1 0.854056319511281

Micro f1 0.8769625046176579

Weigted f1 0.8776046093461484

ROC_acc 0.8579176075736262
---------------------------------------
l2 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.72      0.84      0.78      7620
           1       0.38      0.23      0.29      3209

    accuracy                           0.66     10829
   macro avg       0.55      0.54      0.53     10829
weighted avg       0.62      0.66      0.63     10829


Confusion_Matrix
[[6398 1222]
 [2462  747]]

Macro f1 0.5324923500095625

Micro f1 0.6598023824914582

Weigted f1 0.6318667179581808

ROC_acc 0.5362076721556579
---------------------------------------
l2 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.80      0.76      0.78      9524
           1       0.49      0.54      0.51      4012

    accuracy                           0.70     13536
   macro avg       0.64      0.65      0.65     13536
weighted avg       0.71      0.70      0.70     13536


Confusion_Matrix
[[7235 2289]
 [1837 2175]]

Macro f1 0.6456690539486893

Micro f1 0.6951832151300237

Weigted f1 0.6996062192513602

ROC_acc 0.6508917179582631
---------------------------------------
l3 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       1.00      0.99      1.00     42491
           1       0.78      0.95      0.86       821

    accuracy                           0.99     43312
   macro avg       0.89      0.97      0.93     43312
weighted avg       0.99      0.99      0.99     43312


Confusion_Matrix
[[42265   226]
 [   39   782]]

Macro f1 0.9259934494187909

Micro f1 0.9938816032508312

Weigted f1 0.9941876342699616

ROC_acc 0.9735890907728515
---------------------------------------
l3 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.98      1.00      0.99     10624
           1       0.00      0.00      0.00       205

    accuracy                           0.98     10829
   macro avg       0.49      0.50      0.49     10829
weighted avg       0.96      0.98      0.97     10829


Confusion_Matrix
[[10598    26]
 [  205     0]]

Macro f1 0.494609604704345

Micro f1 0.9786683904330963

Weigted f1 0.9704926475905369

ROC_acc 0.49877635542168675
---------------------------------------
l3 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.98      0.96      0.97     13280
           1       0.04      0.09      0.05       256

    accuracy                           0.94     13536
   macro avg       0.51      0.52      0.51     13536
weighted avg       0.96      0.94      0.95     13536


Confusion_Matrix
[[12687   593]
 [  232    24]]

Macro f1 0.5117465331760912

Micro f1 0.9390514184397163

Weigted f1 0.9512331339558001

ROC_acc 0.5245481927710843
---------------------------------------
l5 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       1.00      0.99      0.99     42726
           1       0.56      0.97      0.71       586

    accuracy                           0.99     43312
   macro avg       0.78      0.98      0.85     43312
weighted avg       0.99      0.99      0.99     43312


Confusion_Matrix
[[42274   452]
 [   16   570]]

Macro f1 0.8517251888669948

Micro f1 0.9891946804580717

Weigted f1 0.9906318734931213

ROC_acc 0.9810586036046184
---------------------------------------
l5 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     10683
           1       0.20      0.01      0.01       146

    accuracy                           0.99     10829
   macro avg       0.59      0.50      0.50     10829
weighted avg       0.98      0.99      0.98     10829


Confusion_Matrix
[[10679     4]
 [  145     1]]

Macro f1 0.5031585280874208

Micro f1 0.9862406501061963

Weigted f1 0.979861685955171

ROC_acc 0.5032374442046575
---------------------------------------
l5 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.99      0.96      0.97     13353
           1       0.03      0.07      0.04       183

    accuracy                           0.95     13536
   macro avg       0.51      0.52      0.51     13536
weighted avg       0.97      0.95      0.96     13536


Confusion_Matrix
[[12858   495]
 [  170    13]]

Macro f1 0.5062095461743917

Micro f1 0.9508717494089834

Weigted f1 0.9621224474277645

ROC_acc 0.5169839650450013
---------------------------------------
l7 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     42893
           1       0.70      0.99      0.82       419

    accuracy                           1.00     43312
   macro avg       0.85      0.99      0.91     43312
weighted avg       1.00      1.00      1.00     43312


Confusion_Matrix
[[42716   177]
 [    6   413]]

Macro f1 0.9082474166537255

Micro f1 0.9957748429996306

Weigted f1 0.996128652183498

ROC_acc 0.990776821737746
---------------------------------------
l7 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     10724
           1       0.00      0.00      0.00       105

    accuracy                           0.99     10829
   macro avg       0.50      0.50      0.50     10829
weighted avg       0.98      0.99      0.99     10829


Confusion_Matrix
[[10723     1]
 [  105     0]]

Macro f1 0.49754083147735706

Micro f1 0.9902114692030658

Weigted f1 0.9854331658995619

ROC_acc 0.49995337560611713
---------------------------------------
l7 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.99      0.98      0.98     13405
           1       0.02      0.05      0.03       131

    accuracy                           0.97     13536
   macro avg       0.51      0.51      0.51     13536
weighted avg       0.98      0.97      0.97     13536


Confusion_Matrix
[[13109   296]
 [  125     6]]

Macro f1 0.5059548646616939

Micro f1 0.9688977541371159

Weigted f1 0.9749393655314758

ROC_acc 0.5118601068873128
---------------------------------------
l11 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.96      0.96      0.96     35895
           1       0.80      0.79      0.80      7417

    accuracy                           0.93     43312
   macro avg       0.88      0.88      0.88     43312
weighted avg       0.93      0.93      0.93     43312


Confusion_Matrix
[[34452  1443]
 [ 1549  5868]]

Macro f1 0.877616935609871

Micro f1 0.9309198374584411

Weigted f1 0.9307221706659716

ROC_acc 0.8754774343238878
---------------------------------------
l11 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.83      0.98      0.90      8975
           1       0.37      0.06      0.11      1854

    accuracy                           0.82     10829
   macro avg       0.60      0.52      0.50     10829
weighted avg       0.76      0.82      0.76     10829


Confusion_Matrix
[[8782  193]
 [1740  114]]

Macro f1 0.5031816259443277

Micro f1 0.8214978299011912

Weigted f1 0.764687127602937

ROC_acc 0.5199922474330891
---------------------------------------
l11 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.87      0.86      0.86     11218
           1       0.36      0.39      0.37      2318

    accuracy                           0.77     13536
   macro avg       0.61      0.62      0.62     13536
weighted avg       0.78      0.77      0.78     13536


Confusion_Matrix
[[9594 1624]
 [1422  896]]

Macro f1 0.6167018003814737

Micro f1 0.7749704491725768

Weigted f1 0.7786460374751524

ROC_acc 0.6208863912936669
---------------------------------------
l13 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     40222
           1       0.78      0.98      0.87      3090

    accuracy                           0.98     43312
   macro avg       0.89      0.98      0.93     43312
weighted avg       0.98      0.98      0.98     43312


Confusion_Matrix
[[39383   839]
 [   77  3013]]

Macro f1 0.92827692902682

Micro f1 0.9788511267085335

Weigted f1 0.9799107235914991

ROC_acc 0.9771108374411981
---------------------------------------
l13 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.93      0.96      0.94     10057
           1       0.14      0.09      0.11       772

    accuracy                           0.89     10829
   macro avg       0.54      0.52      0.53     10829
weighted avg       0.88      0.89      0.88     10829


Confusion_Matrix
[[9614  443]
 [ 700   72]]

Macro f1 0.5278894685403939

Micro f1 0.8944500877273986

Weigted f1 0.8845773064309135

ROC_acc 0.5246076637776075
---------------------------------------
l13 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.95      0.90      0.92     12570
           1       0.23      0.38      0.29       966

    accuracy                           0.86     13536
   macro avg       0.59      0.64      0.61     13536
weighted avg       0.90      0.86      0.88     13536


Confusion_Matrix
[[11327  1243]
 [  597   369]]

Macro f1 0.6055739937387811

Micro f1 0.8640661938534279

Weigted f1 0.8793049200145945

ROC_acc 0.6415506702836785
---------------------------------------
l15 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.95      0.86      0.91     31703
           1       0.70      0.89      0.79     11609

    accuracy                           0.87     43312
   macro avg       0.83      0.88      0.85     43312
weighted avg       0.89      0.87      0.87     43312


Confusion_Matrix
[[27354  4349]
 [ 1294 10315]]

Macro f1 0.8458568775245411

Micro f1 0.8697127816771334

Weigted f1 0.873990015504598

ROC_acc 0.8756776553878323
---------------------------------------
l15 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.75      0.86      0.80      7926
           1       0.36      0.21      0.26      2903

    accuracy                           0.69     10829
   macro avg       0.55      0.54      0.53     10829
weighted avg       0.64      0.69      0.66     10829


Confusion_Matrix
[[6853 1073]
 [2304  599]]

Macro f1 0.5320880087544291

Micro f1 0.6881521839505033

Weigted f1 0.6574334439974545

ROC_acc 0.53548051564467
---------------------------------------
l15 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.82      0.72      0.77      9908
           1       0.43      0.57      0.49      3628

    accuracy                           0.68     13536
   macro avg       0.63      0.65      0.63     13536
weighted avg       0.72      0.68      0.69     13536


Confusion_Matrix
[[7167 2741]
 [1565 2063]]

Macro f1 0.629158896010294

Micro f1 0.6818853427895981

Weigted f1 0.6940339128155508

ROC_acc 0.6459938601617795
---------------------------------------
l17 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       1.00      0.97      0.98     42422
           1       0.36      0.95      0.53       890

    accuracy                           0.96     43312
   macro avg       0.68      0.96      0.75     43312
weighted avg       0.99      0.96      0.97     43312


Confusion_Matrix
[[40952  1470]
 [   46   844]]

Macro f1 0.754334174106869

Micro f1 0.9649981529368304

Weigted f1 0.9724775960866726

ROC_acc 0.9568313875723801
---------------------------------------
l17 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.98      1.00      0.99     10606
           1       0.03      0.00      0.01       223

    accuracy                           0.98     10829
   macro avg       0.50      0.50      0.50     10829
weighted avg       0.96      0.98      0.97     10829


Confusion_Matrix
[[10568    38]
 [  222     1]]

Macro f1 0.4977408918553657

Micro f1 0.9759903961584634

Weigted f1 0.9676627810556176

ROC_acc 0.500450713658146
---------------------------------------
l17 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.98      0.92      0.95     13258
           1       0.03      0.10      0.04       278

    accuracy                           0.90     13536
   macro avg       0.50      0.51      0.50     13536
weighted avg       0.96      0.90      0.93     13536


Confusion_Matrix
[[12202  1056]
 [  249    29]]

Macro f1 0.4958963787000661

Micro f1 0.9035904255319149

Weigted f1 0.9306181997694325

ROC_acc 0.5123332620673713
---------------------------------------
l18 Training results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     42590
           1       0.84      0.94      0.89       722

    accuracy                           1.00     43312
   macro avg       0.92      0.97      0.94     43312
weighted avg       1.00      1.00      1.00     43312


Confusion_Matrix
[[42462   128]
 [   40   682]]

Macro f1 0.9441825459625393

Micro f1 0.9961211673439232

Weigted f1 0.99623056415296

ROC_acc 0.9707964688107115
---------------------------------------
l18 Validation results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.98      1.00      0.99     10648
           1       0.20      0.01      0.01       181

    accuracy                           0.98     10829
   macro avg       0.59      0.50      0.50     10829
weighted avg       0.97      0.98      0.98     10829


Confusion_Matrix
[[10644     4]
 [  180     1]]

Macro f1 0.5010916943095685

Micro f1 0.9830085880506049

Weigted f1 0.9750392773958625

ROC_acc 0.5025746022390012
---------------------------------------
l18 Test results for hyb/cnn with smote on train and original test set
              precision    recall  f1-score   support

           0       0.98      0.97      0.98     13310
           1       0.03      0.06      0.04       226

    accuracy                           0.95     13536
   macro avg       0.51      0.51      0.51     13536
weighted avg       0.97      0.95      0.96     13536


Confusion_Matrix
[[12867   443]
 [  212    14]]

Macro f1 0.5080873297455732

Micro f1 0.9516105200945626

Weigted f1 0.9595817219128633

ROC_acc 0.5143318284874637