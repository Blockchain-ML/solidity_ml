
---------------------------------------
l1 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.98      0.52      0.68     19055
           1       0.10      0.82      0.18      1249

    accuracy                           0.54     20304
   macro avg       0.54      0.67      0.43     20304
weighted avg       0.92      0.54      0.65     20304


Confusion_Matrix
[[9955 9100]
 [ 229 1020]]

Macro f1 0.4301875735795699

Micro f1 0.5405338849487785

Weigted f1 0.6500898030412522

ROC_acc 0.6695441895368828
---------------------------------------
l2 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.83      0.33      0.47     14287
           1       0.35      0.85      0.49      6017

    accuracy                           0.48     20304
   macro avg       0.59      0.59      0.48     20304
weighted avg       0.69      0.48      0.48     20304


Confusion_Matrix
[[4695 9592]
 [ 930 5087]]

Macro f1 0.4815837539833171

Micro f1 0.48177698975571315

Weigted f1 0.4775070707238387

ROC_acc 0.5870291750192542
---------------------------------------
l3 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.98      0.65      0.78     19919
           1       0.02      0.46      0.05       385

    accuracy                           0.65     20304
   macro avg       0.50      0.56      0.41     20304
weighted avg       0.97      0.65      0.77     20304


Confusion_Matrix
[[12937  6982]
 [  207   178]]

Macro f1 0.41487509026234576

Micro f1 0.6459318360914106

Weigted f1 0.7686224429565187

ROC_acc 0.5559090289699256
---------------------------------------
l4 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       1.00      0.95      0.97     20283
           1       0.00      0.10      0.00        21

    accuracy                           0.95     20304
   macro avg       0.50      0.52      0.49     20304
weighted avg       1.00      0.95      0.97     20304


Confusion_Matrix
[[19197  1086]
 [   19     2]]

Macro f1 0.48781573061933453

Micro f1 0.9455772261623325

Weigted f1 0.9710229941094219

ROC_acc 0.5208478599249196
---------------------------------------
l5 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.99      0.67      0.80     20029
           1       0.02      0.41      0.03       275

    accuracy                           0.67     20304
   macro avg       0.50      0.54      0.42     20304
weighted avg       0.98      0.67      0.79     20304


Confusion_Matrix
[[13513  6516]
 [  162   113]]

Macro f1 0.4172989634522511

Micro f1 0.6710992907801419

Weigted f1 0.7914461027086059

ROC_acc 0.5427904084531974
---------------------------------------
l6 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.51      0.42      0.46      8212
           1       0.65      0.72      0.68     12092

    accuracy                           0.60     20304
   macro avg       0.58      0.57      0.57     20304
weighted avg       0.59      0.60      0.59     20304


Confusion_Matrix
[[3484 4728]
 [3346 8746]]

Macro f1 0.5737131057680597

Micro f1 0.602344365642238

Weigted f1 0.5948247151013573

ROC_acc 0.5737726544938231
---------------------------------------
l7 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.99      0.74      0.85     20107
           1       0.01      0.39      0.03       197

    accuracy                           0.74     20304
   macro avg       0.50      0.56      0.44     20304
weighted avg       0.98      0.74      0.84     20304


Confusion_Matrix
[[14926  5181]
 [  121    76]]

Macro f1 0.43852367827668576

Micro f1 0.7388691883372734

Weigted f1 0.8412091399134736

ROC_acc 0.5640576721645795
---------------------------------------
l8 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.99      0.77      0.87     20187
           1       0.01      0.26      0.01       117

    accuracy                           0.77     20304
   macro avg       0.50      0.51      0.44     20304
weighted avg       0.99      0.77      0.86     20304


Confusion_Matrix
[[15563  4624]
 [   87    30]]

Macro f1 0.44055983189027226

Micro f1 0.7679767533490938

Weigted f1 0.8636112458913376

ROC_acc 0.5136759757803003
---------------------------------------
l9 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.89      0.37      0.52     17202
           1       0.17      0.73      0.28      3102

    accuracy                           0.43     20304
   macro avg       0.53      0.55      0.40     20304
weighted avg       0.78      0.43      0.48     20304


Confusion_Matrix
[[ 6362 10840]
 [  826  2276]]

Macro f1 0.4011825046108396

Micro f1 0.4254334121355398

Weigted f1 0.4848677214728738

ROC_acc 0.5517804483622412
---------------------------------------
l10 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       1.00      0.89      0.94     20268
           1       0.01      0.39      0.01        36

    accuracy                           0.89     20304
   macro avg       0.50      0.64      0.48     20304
weighted avg       1.00      0.89      0.94     20304


Confusion_Matrix
[[18073  2195]
 [   22    14]]

Macro f1 0.47734105111371056

Micro f1 0.8908096926713948

Weigted f1 0.9405614706272533

ROC_acc 0.6402950463785277
---------------------------------------
l11 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.94      0.29      0.44     16827
           1       0.21      0.91      0.34      3477

    accuracy                           0.40     20304
   macro avg       0.57      0.60      0.39     20304
weighted avg       0.81      0.40      0.43     20304


Confusion_Matrix
[[ 4893 11934]
 [  325  3152]]

Macro f1 0.39175523192113143

Micro f1 0.3962273443656422

Weigted f1 0.4260474209700803

ROC_acc 0.5986556436656585
---------------------------------------
l12 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.89      0.28      0.42     16600
           1       0.21      0.84      0.33      3704

    accuracy                           0.38     20304
   macro avg       0.55      0.56      0.38     20304
weighted avg       0.76      0.38      0.41     20304


Confusion_Matrix
[[ 4637 11963]
 [  591  3113]]

Macro f1 0.3781950199087727

Micro f1 0.3816981875492514

Weigted f1 0.4078386221998575

ROC_acc 0.559890056988212
---------------------------------------
l13 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.97      0.49      0.65     18856
           1       0.11      0.78      0.19      1448

    accuracy                           0.51     20304
   macro avg       0.54      0.64      0.42     20304
weighted avg       0.91      0.51      0.62     20304


Confusion_Matrix
[[9199 9657]
 [ 312 1136]]

Macro f1 0.41708813662482125

Micro f1 0.5090130023640662

Weigted f1 0.6155537279417971

ROC_acc 0.6361928556527283
---------------------------------------
l14 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.83      0.30      0.45      9663
           1       0.60      0.94      0.73     10641

    accuracy                           0.64     20304
   macro avg       0.72      0.62      0.59     20304
weighted avg       0.71      0.64      0.60     20304


Confusion_Matrix
[[ 2940  6723]
 [  594 10047]]

Macro f1 0.5893095884294

Micro f1 0.6396276595744681

Weigted f1 0.5962338987684849

ROC_acc 0.624215758107717
---------------------------------------
l15 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.86      0.31      0.46     14862
           1       0.31      0.86      0.46      5442

    accuracy                           0.46     20304
   macro avg       0.59      0.59      0.46     20304
weighted avg       0.71      0.46      0.46     20304


Confusion_Matrix
[[ 4662 10200]
 [  758  4684]]

Macro f1 0.4603027548698062

Micro f1 0.46030338849487784

Weigted f1 0.46003144813456376

ROC_acc 0.5871994417735411
---------------------------------------
l16 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.88      0.29      0.44     15498
           1       0.28      0.87      0.42      4806

    accuracy                           0.43     20304
   macro avg       0.58      0.58      0.43     20304
weighted avg       0.74      0.43      0.44     20304


Confusion_Matrix
[[ 4546 10952]
 [  615  4191]]

Macro f1 0.4301350917369424

Micro f1 0.4303092986603625

Weigted f1 0.43538190983611824

ROC_acc 0.5826815638407856
---------------------------------------
l17 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.98      0.59      0.74     19887
           1       0.03      0.52      0.05       417

    accuracy                           0.59     20304
   macro avg       0.50      0.55      0.39     20304
weighted avg       0.96      0.59      0.72     20304


Confusion_Matrix
[[11676  8211]
 [  201   216]]

Macro f1 0.3920092842105371

Micro f1 0.5856973995271868

Weigted f1 0.7210762654684052

ROC_acc 0.5525514118799997
---------------------------------------
l18 results for nb with original Training set and original test set on cw dataset
              precision    recall  f1-score   support

           0       0.99      0.69      0.81     19965
           1       0.02      0.46      0.05       339

    accuracy                           0.69     20304
   macro avg       0.51      0.57      0.43     20304
weighted avg       0.97      0.69      0.80     20304


Confusion_Matrix
[[13792  6173]
 [  184   155]]

Macro f1 0.42960103696297164

Micro f1 0.6869089834515366

Weigted f1 0.7999116447054792

ROC_acc 0.574018027122686