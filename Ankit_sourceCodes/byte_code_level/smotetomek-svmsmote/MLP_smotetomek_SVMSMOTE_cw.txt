
---------------------------------------
l1 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.97      0.98      0.98     19055
           1       0.98      0.97      0.98     19055

    accuracy                           0.98     38110
   macro avg       0.98      0.98      0.98     38110
weighted avg       0.98      0.98      0.98     38110


Confusion_Matrix
[[18761   294]
 [  525 18530]]

Macro f1 0.9785087879390091

Micro f1 0.9785095775387037

Weigted f1 0.978508787939009

ROC_acc 0.9785095775387037
---------------------------------------
l2 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.90      0.98      0.94     14287
           1       0.97      0.90      0.93     14287

    accuracy                           0.94     28574
   macro avg       0.94      0.94      0.94     28574
weighted avg       0.94      0.94      0.94     28574


Confusion_Matrix
[[13932   355]
 [ 1494 12793]]

Macro f1 0.935187841700301

Micro f1 0.9352908238258557

Weigted f1 0.9351878417003009

ROC_acc 0.9352908238258557
---------------------------------------
l3 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.97      0.99      0.98     19919
           1       0.99      0.97      0.98     19919

    accuracy                           0.98     39838
   macro avg       0.98      0.98      0.98     39838
weighted avg       0.98      0.98      0.98     39838


Confusion_Matrix
[[19686   233]
 [  581 19338]]

Macro f1 0.9795656880741321

Micro f1 0.9795672473517747

Weigted f1 0.9795656880741322

ROC_acc 0.9795672473517747
---------------------------------------
l4 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     20283
           1       1.00      1.00      1.00     20283

    accuracy                           1.00     40566
   macro avg       1.00      1.00      1.00     40566
weighted avg       1.00      1.00      1.00     40566


Confusion_Matrix
[[20264    19]
 [    3 20280]]

Macro f1 0.9994576738297476

Micro f1 0.9994576739141152

Weigted f1 0.9994576738297476

ROC_acc 0.9994576739141152
---------------------------------------
l5 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.88      0.99      0.93     20029
           1       0.99      0.87      0.93     20029

    accuracy                           0.93     40058
   macro avg       0.94      0.93      0.93     40058
weighted avg       0.94      0.93      0.93     40058


Confusion_Matrix
[[19919   110]
 [ 2683 17346]]

Macro f1 0.9299872457720861

Micro f1 0.9302760996554995

Weigted f1 0.9299872457720861

ROC_acc 0.9302760996554996
---------------------------------------
l6 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.93      0.88      0.91     12092
           1       0.89      0.93      0.91     12092

    accuracy                           0.91     24184
   macro avg       0.91      0.91      0.91     24184
weighted avg       0.91      0.91      0.91     24184


Confusion_Matrix
[[10674  1418]
 [  807 11285]]

Macro f1 0.9079382596391928

Micro f1 0.9079970228250083

Weigted f1 0.9079382596391927

ROC_acc 0.9079970228250083
---------------------------------------
l7 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.90      1.00      0.95     20107
           1       1.00      0.89      0.94     20107

    accuracy                           0.95     40214
   macro avg       0.95      0.95      0.95     40214
weighted avg       0.95      0.95      0.95     40214


Confusion_Matrix
[[20077    30]
 [ 2137 17970]]

Macro f1 0.9459649566945407

Micro f1 0.946113293877754

Weigted f1 0.9459649566945407

ROC_acc 0.946113293877754
---------------------------------------
l8 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.91      0.99      0.95     20187
           1       0.99      0.90      0.94     20187

    accuracy                           0.94     40374
   macro avg       0.95      0.94      0.94     40374
weighted avg       0.95      0.94      0.94     40374


Confusion_Matrix
[[19973   214]
 [ 2026 18161]]

Macro f1 0.9444067711692314

Micro f1 0.9445187496903948

Weigted f1 0.9444067711692313

ROC_acc 0.9445187496903948
---------------------------------------
l9 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.90      0.95      0.93     17202
           1       0.95      0.89      0.92     17202

    accuracy                           0.92     34404
   macro avg       0.93      0.92      0.92     34404
weighted avg       0.93      0.92      0.92     34404


Confusion_Matrix
[[16405   797]
 [ 1825 15377]]

Macro f1 0.9237198264749007

Micro f1 0.9237879316358563

Weigted f1 0.9237198264749007

ROC_acc 0.9237879316358563
---------------------------------------
l10 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.97      1.00      0.99     20268
           1       1.00      0.97      0.99     20268

    accuracy                           0.99     40536
   macro avg       0.99      0.99      0.99     40536
weighted avg       0.99      0.99      0.99     40536


Confusion_Matrix
[[20245    23]
 [  560 19708]]

Macro f1 0.985615198045571

Micro f1 0.9856177225182554

Weigted f1 0.9856151980455711

ROC_acc 0.9856177225182555
---------------------------------------
l11 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.90      0.97      0.93     16827
           1       0.96      0.89      0.93     16827

    accuracy                           0.93     33654
   macro avg       0.93      0.93      0.93     33654
weighted avg       0.93      0.93      0.93     33654


Confusion_Matrix
[[16257   570]
 [ 1802 15025]]

Macro f1 0.9294234545022988

Micro f1 0.929518036488976

Weigted f1 0.9294234545022988

ROC_acc 0.9295180364889761
---------------------------------------
l12 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.87      0.97      0.91     16600
           1       0.96      0.85      0.90     16600

    accuracy                           0.91     33200
   macro avg       0.92      0.91      0.91     33200
weighted avg       0.92      0.91      0.91     33200


Confusion_Matrix
[[16070   530]
 [ 2458 14142]]

Macro f1 0.9096954577955711

Micro f1 0.91

Weigted f1 0.9096954577955711

ROC_acc 0.9099999999999999
---------------------------------------
l13 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.93      0.98      0.95     18856
           1       0.97      0.93      0.95     18856

    accuracy                           0.95     37712
   macro avg       0.95      0.95      0.95     37712
weighted avg       0.95      0.95      0.95     37712


Confusion_Matrix
[[18386   470]
 [ 1286 17570]]

Macro f1 0.9534147612180273

Micro f1 0.9534365719134493

Weigted f1 0.9534147612180274

ROC_acc 0.9534365719134493
---------------------------------------
l14 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.92      0.92      0.92     10641
           1       0.92      0.92      0.92     10641

    accuracy                           0.92     21282
   macro avg       0.92      0.92      0.92     21282
weighted avg       0.92      0.92      0.92     21282


Confusion_Matrix
[[9759  882]
 [ 875 9766]]

Macro f1 0.9174419608080593

Micro f1 0.9174419697396862

Weigted f1 0.9174419608080594

ROC_acc 0.9174419697396862
---------------------------------------
l15 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.93      0.95      0.94     14862
           1       0.95      0.93      0.94     14862

    accuracy                           0.94     29724
   macro avg       0.94      0.94      0.94     29724
weighted avg       0.94      0.94      0.94     29724


Confusion_Matrix
[[14192   670]
 [ 1020 13842]]

Macro f1 0.9431357034075032

Micro f1 0.9431435876732607

Weigted f1 0.9431357034075033

ROC_acc 0.9431435876732608
---------------------------------------
l16 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.89      0.92      0.91     15498
           1       0.92      0.89      0.90     15498

    accuracy                           0.91     30996
   macro avg       0.91      0.91      0.91     30996
weighted avg       0.91      0.91      0.91     30996


Confusion_Matrix
[[14275  1223]
 [ 1712 13786]]

Macro f1 0.9052867895125968

Micro f1 0.9053103626274359

Weigted f1 0.9052867895125968

ROC_acc 0.9053103626274357
---------------------------------------
l17 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.96      0.98      0.97     19887
           1       0.98      0.95      0.97     19887

    accuracy                           0.97     39774
   macro avg       0.97      0.97      0.97     39774
weighted avg       0.97      0.97      0.97     39774


Confusion_Matrix
[[19505   382]
 [  912 18975]]

Macro f1 0.9674604061016814

Micro f1 0.9674661839392567

Weigted f1 0.9674604061016814

ROC_acc 0.9674661839392567
---------------------------------------
l18 CW results for MLP with SVMSMOTE on test set
              precision    recall  f1-score   support

           0       0.95      1.00      0.97     19965
           1       1.00      0.94      0.97     19965

    accuracy                           0.97     39930
   macro avg       0.97      0.97      0.97     39930
weighted avg       0.97      0.97      0.97     39930


Confusion_Matrix
[[19874    91]
 [ 1103 18862]]

Macro f1 0.9700784512298954

Micro f1 0.9700976709241173

Weigted f1 0.9700784512298956

ROC_acc 0.9700976709241171