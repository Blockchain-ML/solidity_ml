{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID       v1       v2       v3       v4       v5       v6       v7  \\\n",
      "0      10001  0.41463  1.18500  1.12590 -0.63784 -1.60940 -0.19869 -0.23010   \n",
      "1      10002 -1.68950 -0.63024 -0.23417 -2.21810 -0.36157 -0.52164 -0.31883   \n",
      "2      10003 -1.71670  2.40120  0.44570  1.14400 -0.53560 -0.69040  0.39990   \n",
      "3      10004 -0.07260  0.31790 -1.38690  1.83000 -1.08930 -1.15900  0.05750   \n",
      "4      10005  0.32088 -1.08450 -1.15780 -0.63845  1.03060  0.38707  0.95113   \n",
      "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "62178  96207 -1.45150 -0.95600 -0.89920 -0.80340 -0.83730  2.07520 -2.71140   \n",
      "62179  96208  1.27570 -1.32360  2.00620 -1.61870 -0.72743  0.58177 -2.55890   \n",
      "62180  96209  0.35809 -2.22570  0.22366 -2.89240  0.43210 -1.64220 -0.12659   \n",
      "62181  96210  0.40804 -2.27950 -0.83962 -1.03440  1.04950  1.32130  1.27670   \n",
      "62182  96211 -0.74982  0.35505 -0.47464 -2.38330 -1.45550 -0.62356 -1.79640   \n",
      "\n",
      "            v8       v9  ...      v491     v492      v493      v494     v495  \\\n",
      "0     -0.69190 -0.99791  ...  0.038877 -0.81235  0.933330  0.534380  0.75724   \n",
      "1      1.06740  0.75016  ... -1.366200 -0.50756  0.014574  1.254400  1.47300   \n",
      "2      1.63330 -0.43470  ...  0.102600  2.38170  1.318500 -0.866900  0.97240   \n",
      "3      0.72450 -0.47780  ...  0.055500  0.48700  1.390100  1.404000 -2.53400   \n",
      "4      0.30132 -1.08750  ...  0.241960  1.93180 -0.930670  0.757390  0.65279   \n",
      "...        ...      ...  ...       ...      ...       ...       ...      ...   \n",
      "62178  1.63910  0.79040  ... -0.935500 -1.42240 -0.239600 -0.080800  0.35160   \n",
      "62179  0.46077 -2.32850  ... -0.523610  0.74670  0.517040 -0.189150  2.19590   \n",
      "62180 -0.65374 -4.12450  ...  1.970200  3.30630  2.595300 -0.936870 -0.88340   \n",
      "62181  0.71817  1.09210  ... -2.847900  0.23018 -0.046523 -0.976680  0.41813   \n",
      "62182 -2.61440 -0.72109  ... -0.410040  1.77290 -2.027400 -0.076067 -3.03920   \n",
      "\n",
      "          v496      v497     v498     v499         Error_Label  \n",
      "0     -1.03830 -0.758880  0.29875 -1.12810  000000000000000100  \n",
      "1      0.45056 -2.005600  1.19390 -2.21030  000000000000000000  \n",
      "2      0.87710 -1.038700  0.78180  0.56360  000000000000000000  \n",
      "3     -1.77610 -1.188000  1.13680 -0.11580  000000000000000000  \n",
      "4     -0.52051  0.406710  0.36767  1.08240  000000000001000000  \n",
      "...        ...       ...      ...      ...                 ...  \n",
      "62178  0.04230  0.039200 -0.14330 -1.16540  000001000011010000  \n",
      "62179 -0.38150  0.150240 -1.41880 -1.57960  010001000000001000  \n",
      "62180  0.23934 -1.231100 -0.55202 -0.23169  000001000000000000  \n",
      "62181 -0.31383 -1.897800 -0.23670 -0.44662  000001000011010000  \n",
      "62182 -1.61440 -0.097925 -1.14480 -0.12252  000001000011010000  \n",
      "\n",
      "[62183 rows x 501 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv(r'CDS_vectorization_v1.csv',dtype={'Error_Label':object} )\n",
    "print(data)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62183, 501)\n",
      "(62183,)\n"
     ]
    }
   ],
   "source": [
    "# split labels and return new dataframe\n",
    "#Create independent and Dependent Features\n",
    "#data=split_label(data)\n",
    "def split_label_dict(df):\n",
    "    # Change 'label' to whatever naming used in the original DataFrame.\n",
    "    temp_df = df['Error_Label'].str.split(\"\", n = -1, expand = True)\n",
    "    for i in range(1, 19):\n",
    "        df[f'l{6}'] = temp_df[6]\n",
    "        df[f'l{6}'] = pd.to_numeric(df[f'l{6}'])\n",
    "    return df\n",
    "\n",
    "newdata=split_label_dict(data)\n",
    "#print(newdata)\n",
    "#Create independent and Dependent Features\n",
    "columns = newdata.columns.tolist()\n",
    "# Filter the columns to remove data we do not want \n",
    "columns = [c for c in columns if c not in [\"l6\"]]\n",
    "# Store the variable we are predicting \n",
    "target = \"l6\"\n",
    "# Define a random state \n",
    "state = np.random.RandomState(69)\n",
    "X = newdata[columns]\n",
    "Y = newdata[target]\n",
    "# Print the shapes of X & Y\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0        1        2        3        4        5        6        7    \\\n",
      "0      0.41463    1.185   1.1259 -0.63784  -1.6094 -0.19869  -0.2301  -0.6919   \n",
      "1      -1.6895 -0.63024 -0.23417  -2.2181 -0.36157 -0.52164 -0.31883   1.0674   \n",
      "2      -1.7167   2.4012   0.4457    1.144  -0.5356  -0.6904   0.3999   1.6333   \n",
      "3      -0.0726   0.3179  -1.3869     1.83  -1.0893   -1.159   0.0575   0.7245   \n",
      "4      0.32088  -1.0845  -1.1578 -0.63845   1.0306  0.38707  0.95113  0.30132   \n",
      "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "62178  -1.4515   -0.956  -0.8992  -0.8034  -0.8373   2.0752  -2.7114   1.6391   \n",
      "62179   1.2757  -1.3236   2.0062  -1.6187 -0.72743  0.58177  -2.5589  0.46077   \n",
      "62180  0.35809  -2.2257  0.22366  -2.8924   0.4321  -1.6422 -0.12659 -0.65374   \n",
      "62181  0.40804  -2.2795 -0.83962  -1.0344   1.0495   1.3213   1.2767  0.71817   \n",
      "62182 -0.74982  0.35505 -0.47464  -2.3833  -1.4555 -0.62356  -1.7964  -2.6144   \n",
      "\n",
      "           8        9    ...      489       490      491       492       493  \\\n",
      "0     -0.99791  0.48108  ...  -1.2054  0.038877 -0.81235   0.93333   0.53438   \n",
      "1      0.75016  0.62511  ...  0.44461   -1.3662 -0.50756  0.014574    1.2544   \n",
      "2      -0.4347  -1.2028  ...  -0.4563    0.1026   2.3817    1.3185   -0.8669   \n",
      "3      -0.4778   0.4592  ...   1.6507    0.0555    0.487    1.3901     1.404   \n",
      "4      -1.0875  0.20053  ...  -1.7508   0.24196   1.9318  -0.93067   0.75739   \n",
      "...        ...      ...  ...      ...       ...      ...       ...       ...   \n",
      "62178   0.7904   0.6802  ...  -0.8416   -0.9355  -1.4224   -0.2396   -0.0808   \n",
      "62179  -2.3285 -0.17092  ...  -1.8081  -0.52361   0.7467   0.51704  -0.18915   \n",
      "62180  -4.1245   1.6332  ... -0.42186    1.9702   3.3063    2.5953  -0.93687   \n",
      "62181   1.0921  0.92365  ... -0.35977   -2.8479  0.23018 -0.046523  -0.97668   \n",
      "62182 -0.72109  -2.1672  ...   2.6797  -0.41004   1.7729   -2.0274 -0.076067   \n",
      "\n",
      "           494      495       496      497      498  \n",
      "0      0.75724  -1.0383  -0.75888  0.29875  -1.1281  \n",
      "1        1.473  0.45056   -2.0056   1.1939  -2.2103  \n",
      "2       0.9724   0.8771   -1.0387   0.7818   0.5636  \n",
      "3       -2.534  -1.7761    -1.188   1.1368  -0.1158  \n",
      "4      0.65279 -0.52051   0.40671  0.36767   1.0824  \n",
      "...        ...      ...       ...      ...      ...  \n",
      "62178   0.3516   0.0423    0.0392  -0.1433  -1.1654  \n",
      "62179   2.1959  -0.3815   0.15024  -1.4188  -1.5796  \n",
      "62180  -0.8834  0.23934   -1.2311 -0.55202 -0.23169  \n",
      "62181  0.41813 -0.31383   -1.8978  -0.2367 -0.44662  \n",
      "62182  -3.0392  -1.6144 -0.097925  -1.1448 -0.12252  \n",
      "\n",
      "[62183 rows x 499 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "62178    1\n",
      "62179    1\n",
      "62180    1\n",
      "62181    1\n",
      "62182    1\n",
      "Name: l6, Length: 62183, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split labels and return new dataframe\n",
    "#Create independent and Dependent Features\n",
    "#data=split_label(data)\n",
    "def split_label_dict(df):\n",
    "    # Change 'label' to whatever naming used in the original DataFrame.\n",
    "    temp_df = df['Error_Label'].str.split(\"\", n = -1, expand = True)\n",
    "    for i in range(1, 19):\n",
    "        df[f'l{6}'] = temp_df[6]\n",
    "        df[f'l{6}'] = pd.to_numeric(df[f'l{6}'])\n",
    "    return df\n",
    "\n",
    "newdata=split_label_dict(data)\n",
    "#print(newdata)\n",
    "#Create independent and Dependent Features\n",
    "df = newdata.values[:, 1:500]\n",
    "X = pd.DataFrame(df) \n",
    "state = np.random.RandomState(69)\n",
    "Y = newdata[\"l6\"]\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58900, 499) (58900,)\n",
      "Original dataset shape Counter({0: 32733, 1: 29450})\n",
      "Resampled dataset shape Counter({0: 29450, 1: 29450})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, Y)\n",
    "print(X_resampled.shape, y_resampled.shape )\n",
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(Y)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.3,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5276740237691002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l6</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4036</td>\n",
       "      <td>4785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3561</td>\n",
       "      <td>5288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0     1\n",
       "l6               \n",
       "0      4036  4785\n",
       "1      3561  5288"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the classifier into the Training set\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 500)\n",
    "classifier.fit(X_train,y_train)\n",
    "# Predicting the test set results\n",
    "y_predict = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "pd.crosstab(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.55      0.53      8821\n",
      "           1       0.52      0.49      0.50      8849\n",
      "\n",
      "    accuracy                           0.52     17670\n",
      "   macro avg       0.52      0.52      0.52     17670\n",
      "weighted avg       0.52      0.52      0.52     17670\n",
      "\n",
      "0.5165661515024056\n",
      "0.5170345217883419\n",
      "0.5170851429664329\n",
      "[[4843 3978]\n",
      " [4556 4293]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "results=classification_report(y_test,y_predict)\n",
    "macro=f1_score(y_test, y_predict, average='macro')\n",
    "micro=f1_score(y_test, y_predict, average='micro')\n",
    "weighted=f1_score(y_test, y_predict, average='weighted')\n",
    "avg=f1_score(y_test, y_predict)\n",
    "#accuracy_score=accuracy_score(y_test,y_predict)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "roc=roc_auc_score(y_test,y_predict)\n",
    "print(results)\n",
    "print(macro)\n",
    "print(micro)\n",
    "print(roc)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Predicting the test set results\n",
    "Y_Pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix \n",
    "print(accuracy_score(y_test,Y_Pred))\n",
    "cm = confusion_matrix(y_test, Y_Pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test,Y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71156, 501) (71156,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smk = SMOTETomek()\n",
    "X_res,y_res=smk.fit_sample(X_train.astype('float'),y_train)\n",
    "print(X_res.shape,y_res.shape)\n",
    "#print(X_res)\n",
    "#print(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 35578, 1: 7950})\n",
      "Resampled dataset shape Counter({0: 35578, 1: 35578})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(y_train)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "# Fitting the classifier into the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 300, random_state = 200)\n",
    "model=classifier.fit(X_res,y_res)\n",
    "\n",
    "# Save History as Pickle\n",
    "\n",
    "filename = 'models_results/l16RFM_tomek.pickle'\n",
    "with open(filename, 'wb') as fh:\n",
    "    pickle.dump(model, fh)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076655052264808\n",
      "[[14889   371]\n",
      " [ 3217   178]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the test set results\n",
    "Y_Pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix \n",
    "\n",
    "print(accuracy_score(y_test,Y_Pred))\n",
    "cm = confusion_matrix(y_test, Y_Pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14889   371]\n",
      " [ 3217   178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89     15260\n",
      "           1       0.32      0.05      0.09      3395\n",
      "\n",
      "    accuracy                           0.81     18655\n",
      "   macro avg       0.57      0.51      0.49     18655\n",
      "weighted avg       0.73      0.81      0.75     18655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score \n",
    "import pickle\n",
    "results=classification_report(y_test,Y_Pred)\n",
    "#accuracy_score=accuracy_score(y_test,Y_Pred)\n",
    "cm = confusion_matrix(y_test, Y_Pred)\n",
    "print(cm)\n",
    "print(results) \n",
    "#print(accuracy_score)\n",
    "\n",
    "# Save Results as Pickle\n",
    "filename = 'models_results/l16RFtomek.pickle'\n",
    "with open(filename, 'wb') as fh:\n",
    "    pickle.dump([results, cm], fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f24ba6e37d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# take the second column because the classifier outputs scores for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# the 0 class as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_Pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# fpr means false-positive-rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# take the second column because the classifier outputs scores for\n",
    "# the 0 class as well\n",
    "preds = Y_Pred[:,1]\n",
    "\n",
    "# fpr means false-positive-rate\n",
    "# tpr means true-positive-rate\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "auc_score = metrics.auc(fpr, tpr)\n",
    "\n",
    "# clear current figure\n",
    "plt.clf()\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_score))\n",
    "\n",
    "# it's helpful to add a diagonal to indicate where chance \n",
    "# scores lie (i.e. just flipping a coin)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
