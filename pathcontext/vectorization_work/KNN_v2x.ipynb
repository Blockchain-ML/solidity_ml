{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv(r'/home/supriya/CDS_vectorization_v2x.csv',dtype={'Error_Label':object} )\n",
    "print(data.shape)\n",
    "#data.head()\n",
    "\n",
    "ERROR_LABEL=14\n",
    "\n",
    "\n",
    "\n",
    "# split labels and return new dataframe\n",
    "#Create independent and Dependent Features\n",
    "\n",
    "def split_label_dict(df):\n",
    "    # Change 'label' to whatever naming used in the original DataFrame.\n",
    "    temp_df = df['Error_Label'].str.split(\"\", n = -1, expand = True)\n",
    "    for i in range(1, 19):\n",
    "        df[f'l{ERROR_LABEL}'] = temp_df[ERROR_LABEL]\n",
    "        df[f'l{ERROR_LABEL}'] = pd.to_numeric(df[f'l{ERROR_LABEL}'])\n",
    "    return df\n",
    "\n",
    "newdata=split_label_dict(data)\n",
    "#print(newdata)\n",
    "#Create independent and Dependent Features\n",
    "df = pd.DataFrame(data)\n",
    "new_df = df.drop(['Error_Label','ID'],axis=1)\n",
    "X = new_df\n",
    "# Store the variable we are predicting \n",
    "Y = newdata[f\"l{ERROR_LABEL}\"]\n",
    "\n",
    "# Print the shapes of X & Y\n",
    "print(X.shape,Y.shape)\n",
    "print(X)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=42,stratify=Y)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smk = SMOTETomek()\n",
    "X_res,y_res=smk.fit_sample(X_train.astype('float'),y_train)\n",
    "print(X_res.shape,y_res.shape)\n",
    "#print(X_res)\n",
    "#print(y_res)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "## Hyperparameter optimization using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import xgboost\n",
    "\n",
    "classifier= xgboost.XGBClassifier(eta=0.8,min_child_weight=5,max_depth=50,max_delta_step=8,reg_alpha=2,grow_policy='lossguide',subsample=0.6,tree_method='approx',max_leaves=1)\n",
    "model=classifier.fit(X_res, y_res)\n",
    "# Predicting the test set results\n",
    "y_predict = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "pd.crosstab(y_test,y_predict)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "results=classification_report(y_test,y_predict)\n",
    "accuracy_score=accuracy_score(y_test,y_predict)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "roc=roc_auc_score(y_test,y_predict)\n",
    "\n",
    "print(cm)\n",
    "print(results) \n",
    "#print(accuracy_score)\n",
    "\n",
    "# Save Results as txt\n",
    "filename = '/home/supriya/pathcontext/vectorization_work/xgboost/xgboost_SMOTETomek_v2x/l{ERROR_LABEL}comb_SMOTETomek_results.txt'\n",
    "with open(filename, 'a') as fh:\n",
    "    fh.write(str(results)+\"\\n\" +\"ROC_ACCuracy:  \"+str(roc) +\"\\n\"+\"Confusion_Matrix\"+\"\\n\"+str(cm)+\"\\n\"+\"accuracy_score: \"+str(accuracy_score))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67677, 501)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv(r'/home/supriya/CDS_vectorization_v2x.csv',dtype={'Error_Label':object} )\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            v1       v2       v3       v4        v5       v6        v7  \\\n",
      "0      0.41463  1.18500  1.12590 -0.63784 -1.609400 -0.19869 -0.230100   \n",
      "1      0.32088 -1.08450 -1.15780 -0.63845  1.030600  0.38707  0.951130   \n",
      "2     -1.21220  0.54410  0.33130  1.34610 -0.044000 -0.68850 -2.005400   \n",
      "3     -0.94921  0.58352 -0.38527 -1.02860 -1.658500  0.23852 -1.198100   \n",
      "4      0.05630  1.40680  0.39810  0.29180 -0.269900 -0.66170 -1.557600   \n",
      "...        ...      ...      ...      ...       ...      ...       ...   \n",
      "67672  0.57810 -3.40390  1.62580 -0.33680  2.292200 -1.02060 -0.836500   \n",
      "67673 -2.12190 -2.21790 -2.69700  2.89430  1.364600  1.37550  0.255070   \n",
      "67674 -1.60550  0.50686 -0.49615 -0.52569 -0.071134 -1.77820  0.008866   \n",
      "67675 -1.04400 -1.67610  0.18878  2.53450  0.071368  0.99836 -0.079039   \n",
      "67676  1.83510  3.37730  1.35650 -0.69700 -1.715700 -2.39180 -0.266600   \n",
      "\n",
      "            v8        v9      v10  ...      v490      v491     v492     v493  \\\n",
      "0     -0.69190 -0.997910  0.48108  ... -1.205400  0.038877 -0.81235  0.93333   \n",
      "1      0.30132 -1.087500  0.20053  ... -1.750800  0.241960  1.93180 -0.93067   \n",
      "2      0.73690  0.560400 -0.51530  ...  0.010600  1.059800 -0.10710  0.61830   \n",
      "3     -0.40317  0.067658 -0.71762  ... -0.713700 -1.821300  0.17340 -0.41185   \n",
      "4     -0.99460  0.196800  0.00470  ...  0.459600  0.842800  1.62770 -0.26780   \n",
      "...        ...       ...      ...  ...       ...       ...      ...      ...   \n",
      "67672  1.82930 -1.098700 -1.09190  ... -1.359400 -0.832000 -0.22600  1.47880   \n",
      "67673  1.41490  0.795840 -1.63350  ...  0.080431  1.583500 -1.88170  2.48220   \n",
      "67674 -2.12290  2.034100 -0.77582  ...  1.273100 -0.507540  1.28740  1.18410   \n",
      "67675 -0.21103 -1.345300 -0.28241  ... -1.426100 -1.633900  0.40216 -2.68070   \n",
      "67676  1.94020 -0.968500  0.43020  ... -1.448600 -1.212800  1.50370 -3.12570   \n",
      "\n",
      "          v494     v495     v496     v497     v498     v499  \n",
      "0      0.53438  0.75724 -1.03830 -0.75888  0.29875 -1.12810  \n",
      "1      0.75739  0.65279 -0.52051  0.40671  0.36767  1.08240  \n",
      "2      0.23710 -0.87250  0.65700  0.80120  1.20850  1.42900  \n",
      "3     -1.59770  0.47807  0.10563  0.16566  0.17695  0.52383  \n",
      "4      0.32460  0.85910 -1.50910  2.04660 -1.06940 -0.93920  \n",
      "...        ...      ...      ...      ...      ...      ...  \n",
      "67672 -0.09060 -0.28330 -0.70680 -0.04070 -0.36110  2.33600  \n",
      "67673 -0.43263 -0.22688  1.02820 -1.06770 -0.85705 -0.01094  \n",
      "67674 -2.58820 -2.18820  2.25200 -2.25460 -2.16660 -0.92128  \n",
      "67675 -1.14220  1.50420 -0.43057  1.53480 -1.71210  0.65452  \n",
      "67676 -0.98790  3.05160  1.23530 -2.13500  1.48730 -0.48870  \n",
      "\n",
      "[67677 rows x 499 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "67672    0\n",
      "67673    0\n",
      "67674    1\n",
      "67675    0\n",
      "67676    0\n",
      "Name: l6, Length: 67677, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split labels and return new dataframe\n",
    "#Create independent and Dependent Features\n",
    "ERROR_LABEL=6\n",
    "def split_label_dict(df):\n",
    "    # Change 'label' to whatever naming used in the original DataFrame.\n",
    "    temp_df = df['Error_Label'].str.split(\"\", n = -1, expand = True)\n",
    "    for i in range(1, 19):\n",
    "        df[f'l{i}'] = temp_df[i]\n",
    "        df[f'l{i}'] = pd.to_numeric(df[f'l{i}'])\n",
    "    return df\n",
    "\n",
    "newdata=split_label_dict(data)\n",
    "#print(newdata)\n",
    "#Create independent and Dependent Features\n",
    "df = pd.DataFrame(data)\n",
    "new_df = df.drop(['Error_Label','l18','l17','l16','l15','l14','l13','l12','l11','l10','l9','l8','l7','l6','l5','l3','l4','l2','l1', 'ID'],axis=1)\n",
    "#new_df = data.drop(['Error_Label','ID'],axis=1)\n",
    "X = new_df\n",
    "# Store the variable we are predicting \n",
    "Y = newdata[f\"l{ERROR_LABEL}\"]\n",
    "\n",
    "# Print the shapes of X & Y\n",
    "#print(X.shape,Y.shape)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
