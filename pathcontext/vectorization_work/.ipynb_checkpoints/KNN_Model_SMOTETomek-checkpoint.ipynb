{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID       v1       v2       v3       v4       v5       v6       v7  \\\n",
      "0      10001  0.41463  1.18500  1.12590 -0.63784 -1.60940 -0.19869 -0.23010   \n",
      "1      10002 -1.68950 -0.63024 -0.23417 -2.21810 -0.36157 -0.52164 -0.31883   \n",
      "2      10003 -1.71670  2.40120  0.44570  1.14400 -0.53560 -0.69040  0.39990   \n",
      "3      10004 -0.07260  0.31790 -1.38690  1.83000 -1.08930 -1.15900  0.05750   \n",
      "4      10005  0.32088 -1.08450 -1.15780 -0.63845  1.03060  0.38707  0.95113   \n",
      "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "62178  96207 -1.45150 -0.95600 -0.89920 -0.80340 -0.83730  2.07520 -2.71140   \n",
      "62179  96208  1.27570 -1.32360  2.00620 -1.61870 -0.72743  0.58177 -2.55890   \n",
      "62180  96209  0.35809 -2.22570  0.22366 -2.89240  0.43210 -1.64220 -0.12659   \n",
      "62181  96210  0.40804 -2.27950 -0.83962 -1.03440  1.04950  1.32130  1.27670   \n",
      "62182  96211 -0.74982  0.35505 -0.47464 -2.38330 -1.45550 -0.62356 -1.79640   \n",
      "\n",
      "            v8       v9  ...      v491     v492      v493      v494     v495  \\\n",
      "0     -0.69190 -0.99791  ...  0.038877 -0.81235  0.933330  0.534380  0.75724   \n",
      "1      1.06740  0.75016  ... -1.366200 -0.50756  0.014574  1.254400  1.47300   \n",
      "2      1.63330 -0.43470  ...  0.102600  2.38170  1.318500 -0.866900  0.97240   \n",
      "3      0.72450 -0.47780  ...  0.055500  0.48700  1.390100  1.404000 -2.53400   \n",
      "4      0.30132 -1.08750  ...  0.241960  1.93180 -0.930670  0.757390  0.65279   \n",
      "...        ...      ...  ...       ...      ...       ...       ...      ...   \n",
      "62178  1.63910  0.79040  ... -0.935500 -1.42240 -0.239600 -0.080800  0.35160   \n",
      "62179  0.46077 -2.32850  ... -0.523610  0.74670  0.517040 -0.189150  2.19590   \n",
      "62180 -0.65374 -4.12450  ...  1.970200  3.30630  2.595300 -0.936870 -0.88340   \n",
      "62181  0.71817  1.09210  ... -2.847900  0.23018 -0.046523 -0.976680  0.41813   \n",
      "62182 -2.61440 -0.72109  ... -0.410040  1.77290 -2.027400 -0.076067 -3.03920   \n",
      "\n",
      "          v496      v497     v498     v499         Error_Label  \n",
      "0     -1.03830 -0.758880  0.29875 -1.12810  000000000000000100  \n",
      "1      0.45056 -2.005600  1.19390 -2.21030  000000000000000000  \n",
      "2      0.87710 -1.038700  0.78180  0.56360  000000000000000000  \n",
      "3     -1.77610 -1.188000  1.13680 -0.11580  000000000000000000  \n",
      "4     -0.52051  0.406710  0.36767  1.08240  000000000001000000  \n",
      "...        ...       ...      ...      ...                 ...  \n",
      "62178  0.04230  0.039200 -0.14330 -1.16540  000001000011010000  \n",
      "62179 -0.38150  0.150240 -1.41880 -1.57960  010001000000001000  \n",
      "62180  0.23934 -1.231100 -0.55202 -0.23169  000001000000000000  \n",
      "62181 -0.31383 -1.897800 -0.23670 -0.44662  000001000011010000  \n",
      "62182 -1.61440 -0.097925 -1.14480 -0.12252  000001000011010000  \n",
      "\n",
      "[62183 rows x 501 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv(r'CDS_vectorization_v1.csv',dtype={'Error_Label':object} )\n",
    "print(data)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0        1        2        3        4        5        6        7    \\\n",
      "0      0.41463    1.185   1.1259 -0.63784  -1.6094 -0.19869  -0.2301  -0.6919   \n",
      "1      -1.6895 -0.63024 -0.23417  -2.2181 -0.36157 -0.52164 -0.31883   1.0674   \n",
      "2      -1.7167   2.4012   0.4457    1.144  -0.5356  -0.6904   0.3999   1.6333   \n",
      "3      -0.0726   0.3179  -1.3869     1.83  -1.0893   -1.159   0.0575   0.7245   \n",
      "4      0.32088  -1.0845  -1.1578 -0.63845   1.0306  0.38707  0.95113  0.30132   \n",
      "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "62178  -1.4515   -0.956  -0.8992  -0.8034  -0.8373   2.0752  -2.7114   1.6391   \n",
      "62179   1.2757  -1.3236   2.0062  -1.6187 -0.72743  0.58177  -2.5589  0.46077   \n",
      "62180  0.35809  -2.2257  0.22366  -2.8924   0.4321  -1.6422 -0.12659 -0.65374   \n",
      "62181  0.40804  -2.2795 -0.83962  -1.0344   1.0495   1.3213   1.2767  0.71817   \n",
      "62182 -0.74982  0.35505 -0.47464  -2.3833  -1.4555 -0.62356  -1.7964  -2.6144   \n",
      "\n",
      "           8        9    ...      489       490      491       492       493  \\\n",
      "0     -0.99791  0.48108  ...  -1.2054  0.038877 -0.81235   0.93333   0.53438   \n",
      "1      0.75016  0.62511  ...  0.44461   -1.3662 -0.50756  0.014574    1.2544   \n",
      "2      -0.4347  -1.2028  ...  -0.4563    0.1026   2.3817    1.3185   -0.8669   \n",
      "3      -0.4778   0.4592  ...   1.6507    0.0555    0.487    1.3901     1.404   \n",
      "4      -1.0875  0.20053  ...  -1.7508   0.24196   1.9318  -0.93067   0.75739   \n",
      "...        ...      ...  ...      ...       ...      ...       ...       ...   \n",
      "62178   0.7904   0.6802  ...  -0.8416   -0.9355  -1.4224   -0.2396   -0.0808   \n",
      "62179  -2.3285 -0.17092  ...  -1.8081  -0.52361   0.7467   0.51704  -0.18915   \n",
      "62180  -4.1245   1.6332  ... -0.42186    1.9702   3.3063    2.5953  -0.93687   \n",
      "62181   1.0921  0.92365  ... -0.35977   -2.8479  0.23018 -0.046523  -0.97668   \n",
      "62182 -0.72109  -2.1672  ...   2.6797  -0.41004   1.7729   -2.0274 -0.076067   \n",
      "\n",
      "           494      495       496      497      498  \n",
      "0      0.75724  -1.0383  -0.75888  0.29875  -1.1281  \n",
      "1        1.473  0.45056   -2.0056   1.1939  -2.2103  \n",
      "2       0.9724   0.8771   -1.0387   0.7818   0.5636  \n",
      "3       -2.534  -1.7761    -1.188   1.1368  -0.1158  \n",
      "4      0.65279 -0.52051   0.40671  0.36767   1.0824  \n",
      "...        ...      ...       ...      ...      ...  \n",
      "62178   0.3516   0.0423    0.0392  -0.1433  -1.1654  \n",
      "62179   2.1959  -0.3815   0.15024  -1.4188  -1.5796  \n",
      "62180  -0.8834  0.23934   -1.2311 -0.55202 -0.23169  \n",
      "62181  0.41813 -0.31383   -1.8978  -0.2367 -0.44662  \n",
      "62182  -3.0392  -1.6144 -0.097925  -1.1448 -0.12252  \n",
      "\n",
      "[62183 rows x 499 columns]\n",
      "0        1\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "62178    0\n",
      "62179    0\n",
      "62180    0\n",
      "62181    0\n",
      "62182    0\n",
      "Name: l16, Length: 62183, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split labels and return new dataframe\n",
    "#Create independent and Dependent Features\n",
    "#data=split_label(data)\n",
    "def split_label_dict(df):\n",
    "    # Change 'label' to whatever naming used in the original DataFrame.\n",
    "    temp_df = df['Error_Label'].str.split(\"\", n = -1, expand = True)\n",
    "    for i in range(1, 19):\n",
    "        df[f'l{16}'] = temp_df[16]\n",
    "        df[f'l{16}'] = pd.to_numeric(df[f'l{16}'])\n",
    "    return df\n",
    "\n",
    "newdata=split_label_dict(data)\n",
    "#print(newdata)\n",
    "#Create independent and Dependent Features\n",
    "#columns = newdata.columns.tolist()\n",
    "df = newdata.values[:, 1:500]\n",
    "X = pd.DataFrame(df)\n",
    "# Filter the columns to remove data we do not want \n",
    "#columns = [c for c in columns if c not in [\"l1\"]]\n",
    "# Store the variable we are predicting \n",
    "#target = \"l16\"\n",
    "# Define a random state \n",
    "state = np.random.RandomState(69)\n",
    "#X = newdata[columns]\n",
    "Y = newdata[\"l16\"]\n",
    "# Print the shapes of X & Y\n",
    "#print(X.shape, Y.shape)\n",
    "#print(X)\n",
    "#df = pd.DataFrame(X)\n",
    "print(X)\n",
    "#print(newdata)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "62178    0\n",
      "62179    0\n",
      "62180    0\n",
      "62181    0\n",
      "62182    0\n",
      "Name: l16, Length: 62183, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import collections\n",
    "v1=newdata['l16']\n",
    "\n",
    "#hi=collections.Counter(v1)\n",
    "#print(hi)\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22690, 499) (22690,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, Y)\n",
    "print(X_resampled.shape, y_resampled.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 50838, 1: 11345})\n",
      "Resampled dataset shape Counter({0: 11345, 1: 11345})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(Y)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "62178    0\n",
      "62179    0\n",
      "62180    0\n",
      "62181    0\n",
      "62182    0\n",
      "Name: l16, Length: 62183, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def prog(X, Y, percent=0.8):\n",
    "    X[\"Label\"]=Y\n",
    "    print(Y)\n",
    "    size0, size1=X[( (X[\"Label\"]==0) )].shape[0], X[( (X[\"Label\"]==1) )].shape[0]\n",
    "    sz=[size0, size1]; Label=[0, 1]\n",
    "    mn=min(sz); index=sz.index(mn)\n",
    "    mn8=int(percent*mn)\n",
    "    \n",
    "    tr_labelA=X[( (X[\"Label\"]==Label[index]) )][:mn8]\n",
    "    tr_labelB=X[( (X[\"Label\"]==Label[(index+1)%2]) )][:mn8]\n",
    "    ts_labelA=X[( (X[\"Label\"]==Label[index]) )][mn8:] \n",
    "    ts_labelB=X[( (X[\"Label\"]==Label[(index+1)%2]) )][mn8:]\n",
    "    X=pd.concat([tr_labelA, tr_labelB])\n",
    "    \n",
    "    Xts=pd.concat([ts_labelA, ts_labelB])\n",
    "    \n",
    "    Y=X[\"Label\"]\n",
    "    Yts=Xts[\"Label\"]\n",
    "    del X[\"Label\"]\n",
    "    del Xts[\"Label\"]\n",
    "    return X, Xts, Y, Yts\n",
    "\n",
    "X_train, X_test, y_train, y_test=prog(X, Y, percent=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.3,random_state=69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    score=cross_val_score(knn,X,Y,cv=10)\n",
    "    accuracy_rate.append(score.mean())\n",
    "print(accuracy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5005141765829293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l16</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0  1\n",
       "l16           \n",
       "0      3407  1\n",
       "1      3399  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Fitting the classifier into the Training set\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "# Predicting the test set results\n",
    "y_predict = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "pd.crosstab(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3408\n",
      "           1       0.00      0.00      0.00      3399\n",
      "\n",
      "    accuracy                           0.50      6807\n",
      "   macro avg       0.25      0.50      0.33      6807\n",
      "weighted avg       0.25      0.50      0.33      6807\n",
      "\n",
      "0.33356177795183084\n",
      "0.5005141765829293\n",
      "0.4998532863849765\n",
      "[[3407    1]\n",
      " [3399    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "results=classification_report(y_test,y_predict)\n",
    "macro=f1_score(y_test, y_predict, average='macro')\n",
    "micro=f1_score(y_test, y_predict, average='micro')\n",
    "weighted=f1_score(y_test, y_predict, average='weighted')\n",
    "avg=f1_score(y_test, y_predict)\n",
    "#accuracy_score=accuracy_score(y_test,y_predict)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "roc=roc_auc_score(y_test,y_predict)\n",
    "print(results)\n",
    "print(macro)\n",
    "print(micro)\n",
    "print(roc)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "  #       markerfacecolor='red', markersize=10)\n",
    "plt.plot(range(1,40),accuracy_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "smk = SMOTETomek()\n",
    "X_res,y_res=smk.fit_sample(X_train.astype('float'),y_train)\n",
    "print(X_res.shape,y_res.shape)\n",
    "#print(X_res)\n",
    "#print(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(y_train)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Fitting the classifier into the Training set\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_res,y_res)\n",
    "# Predicting the test set results\n",
    "y_predict = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "pd.crosstab(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     15260\n",
      "           1       0.00      0.00      0.00      3395\n",
      "\n",
      "    accuracy                           0.82     18655\n",
      "   macro avg       0.41      0.50      0.45     18655\n",
      "weighted avg       0.67      0.82      0.74     18655\n",
      "\n",
      "0.8180112570356473\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supriya/.pyenv/versions/3.7.2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "roc=roc_auc_score(y_test,y_predict)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
