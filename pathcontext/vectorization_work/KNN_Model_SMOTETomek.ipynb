{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>l9</th>\n",
       "      <th>l10</th>\n",
       "      <th>l11</th>\n",
       "      <th>l12</th>\n",
       "      <th>l13</th>\n",
       "      <th>l14</th>\n",
       "      <th>l15</th>\n",
       "      <th>l16</th>\n",
       "      <th>l17</th>\n",
       "      <th>l18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.41463</td>\n",
       "      <td>1.18500</td>\n",
       "      <td>1.12590</td>\n",
       "      <td>-0.63784</td>\n",
       "      <td>-1.60940</td>\n",
       "      <td>-0.19869</td>\n",
       "      <td>-0.23010</td>\n",
       "      <td>-0.69190</td>\n",
       "      <td>-0.99791</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>-1.68950</td>\n",
       "      <td>-0.63024</td>\n",
       "      <td>-0.23417</td>\n",
       "      <td>-2.21810</td>\n",
       "      <td>-0.36157</td>\n",
       "      <td>-0.52164</td>\n",
       "      <td>-0.31883</td>\n",
       "      <td>1.06740</td>\n",
       "      <td>0.75016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>-1.71670</td>\n",
       "      <td>2.40120</td>\n",
       "      <td>0.44570</td>\n",
       "      <td>1.14400</td>\n",
       "      <td>-0.53560</td>\n",
       "      <td>-0.69040</td>\n",
       "      <td>0.39990</td>\n",
       "      <td>1.63330</td>\n",
       "      <td>-0.43470</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>-0.07260</td>\n",
       "      <td>0.31790</td>\n",
       "      <td>-1.38690</td>\n",
       "      <td>1.83000</td>\n",
       "      <td>-1.08930</td>\n",
       "      <td>-1.15900</td>\n",
       "      <td>0.05750</td>\n",
       "      <td>0.72450</td>\n",
       "      <td>-0.47780</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>0.32088</td>\n",
       "      <td>-1.08450</td>\n",
       "      <td>-1.15780</td>\n",
       "      <td>-0.63845</td>\n",
       "      <td>1.03060</td>\n",
       "      <td>0.38707</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.30132</td>\n",
       "      <td>-1.08750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4060 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID       v1       v2       v3       v4       v5       v6       v7  \\\n",
       "0  10001  0.41463  1.18500  1.12590 -0.63784 -1.60940 -0.19869 -0.23010   \n",
       "1  10002 -1.68950 -0.63024 -0.23417 -2.21810 -0.36157 -0.52164 -0.31883   \n",
       "2  10003 -1.71670  2.40120  0.44570  1.14400 -0.53560 -0.69040  0.39990   \n",
       "3  10004 -0.07260  0.31790 -1.38690  1.83000 -1.08930 -1.15900  0.05750   \n",
       "4  10005  0.32088 -1.08450 -1.15780 -0.63845  1.03060  0.38707  0.95113   \n",
       "\n",
       "        v8       v9  ...  l9  l10  l11  l12  l13  l14  l15  l16  l17  l18  \n",
       "0 -0.69190 -0.99791  ...   0    0    0    0    0    0    0    1    0    0  \n",
       "1  1.06740  0.75016  ...   0    0    0    0    0    0    0    0    0    0  \n",
       "2  1.63330 -0.43470  ...   0    0    0    0    0    0    0    0    0    0  \n",
       "3  0.72450 -0.47780  ...   0    0    0    0    0    0    0    0    0    0  \n",
       "4  0.30132 -1.08750  ...   0    0    0    1    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 4060 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv(r'vect_fv.csv',dtype={'error_label':object} )\n",
    "#print(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels and return new dataframe\n",
    "#Create independent and Dependent Features\n",
    "#data=split_label(data)\n",
    "def split_label_dict(df):\n",
    "    # Change 'label' to whatever naming used in the original DataFrame.\n",
    "    temp_df = df['error_label'].str.split(\"\", n = -1, expand = True)\n",
    "    for i in range(1, 19):\n",
    "        df[f'l{6}'] = temp_df[6]\n",
    "        df[f'l{6}'] = pd.to_numeric(df[f'l{6}'])\n",
    "    return df\n",
    "\n",
    "newdata=split_label_dict(data)\n",
    "#print(newdata)\n",
    "#Create independent and Dependent Features\n",
    "df = newdata.values[:, 1:4040]\n",
    "X = pd.DataFrame(df) \n",
    "Y = newdata[\"l6\"]\n",
    "#print(X)\n",
    "#print(Y)\n",
    "#X.head()\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.values[:, 1:4040]\n",
    "X = pd.DataFrame(df) \n",
    "Y = data[\"l17\"]\n",
    "#print(X)\n",
    "#print(Y)\n",
    "X.head()\n",
    "#Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62183, 4040)\n",
      "(62183, 4040)\n",
      "(62183,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "#print df\n",
    "new_df = df.drop(['error_label','l18','l17','l16','l15','l14','l13','l12','l11','l10','l9','l8','l7','l6','l5','l3','l4','l2','l1', 'ID'],axis=1)\n",
    "Y = data[\"l14\"]\n",
    "X=new_df\n",
    "print(new_df.shape)\n",
    "print(X.shape)\n",
    "#print(new_df)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, Y)\n",
    "print(X_resampled.shape, y_resampled.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(Y)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prog(X, Y, percent=0.8):\n",
    "    X[\"Label\"]=Y\n",
    "    print(Y)\n",
    "    size0, size1=X[( (X[\"Label\"]==0) )].shape[0], X[( (X[\"Label\"]==1) )].shape[0]\n",
    "    sz=[size0, size1]; Label=[0, 1]\n",
    "    mn=min(sz); index=sz.index(mn)\n",
    "    mn8=int(percent*mn)\n",
    "    \n",
    "    tr_labelA=X[( (X[\"Label\"]==Label[index]) )][:mn8]\n",
    "    tr_labelB=X[( (X[\"Label\"]==Label[(index+1)%2]) )][:mn8]\n",
    "    ts_labelA=X[( (X[\"Label\"]==Label[index]) )][mn8:] \n",
    "    ts_labelB=X[( (X[\"Label\"]==Label[(index+1)%2]) )][mn8:]\n",
    "    X=pd.concat([tr_labelA, tr_labelB])\n",
    "    \n",
    "    Xts=pd.concat([ts_labelA, ts_labelB])\n",
    "    \n",
    "    Y=X[\"Label\"]\n",
    "    Yts=Xts[\"Label\"]\n",
    "    del X[\"Label\"]\n",
    "    del Xts[\"Label\"]\n",
    "    return X, Xts, Y, Yts\n",
    "\n",
    "X_train, X_test, y_train, y_test=prog(X, Y, percent=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=69,stratify=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    score=cross_val_score(knn,X,Y,cv=10)\n",
    "    accuracy_rate.append(score.mean())\n",
    "print(accuracy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Fitting the classifier into the Training set\n",
    "model = KNeighborsClassifier(n_neighbors=30)\n",
    "model.fit(X_train,y_train)\n",
    "# Predicting the test set results\n",
    "y_predict = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "pd.crosstab(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "results=classification_report(y_test,y_predict)\n",
    "macro=f1_score(y_test, y_predict, average='macro')\n",
    "micro=f1_score(y_test, y_predict, average='micro')\n",
    "weighted=f1_score(y_test, y_predict, average='weighted')\n",
    "avg=f1_score(y_test, y_predict)\n",
    "#accuracy_score=accuracy_score(y_test,y_predict)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "roc=roc_auc_score(y_test,y_predict)\n",
    "print(results)\n",
    "print(macro)\n",
    "print(micro)\n",
    "print(roc)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "  #       markerfacecolor='red', markersize=10)\n",
    "plt.plot(range(1,40),accuracy_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "smk = SMOTE()\n",
    "#smk = SMOTETomek()\n",
    "X_res,y_res=smk.fit_sample(X_train.astype('float'),y_train)\n",
    "print(X_res.shape,y_res.shape)\n",
    "#print(X_res)\n",
    "#print(y_res)\n",
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(y_train)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Fitting the classifier into the Training set\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_res,y_res)\n",
    "# Predicting the Training set results\n",
    "#y_train_predict=model.predict(X_res)\n",
    "# Predicting the test set results\n",
    "y_predict = model.predict(X_test)\n",
    "#print(accuracy_score(y_res,y_train_predict))\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "pd.crosstab(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_test, y_test)\n",
    "print(X_resampled.shape, y_resampled.shape )\n",
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(y_test)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_predict = model.predict(X_resampled)\n",
    "print(accuracy_score(y_resampled,y_predict))\n",
    "pd.crosstab(y_resampled,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(classification_report(y_resampled,y_predict))\n",
    "print(accuracy_score(y_resampled,y_predict))\n",
    "roc=roc_auc_score(y_resampled,y_predict)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "results=classification_report(y_test,y_predict)\n",
    "macro=f1_score(y_test, y_predict, average='macro')\n",
    "micro=f1_score(y_test, y_predict, average='micro')\n",
    "weighted=f1_score(y_test, y_predict, average='weighted')\n",
    "avg=f1_score(y_test, y_predict, average=None)\n",
    "\n",
    "accuracy_score=accuracy_score(y_test,y_predict)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "roc=roc_auc_score(y_test,y_predict)\n",
    "\n",
    "print(cm)\n",
    "print(results) \n",
    "print(roc)\n",
    "#print(accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
