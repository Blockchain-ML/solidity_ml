{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID       v1       v2       v3       v4       v5       v6       v7  \\\n",
      "0      10001  0.41463  1.18500  1.12590 -0.63784 -1.60940 -0.19869 -0.23010   \n",
      "1      10002 -1.68950 -0.63024 -0.23417 -2.21810 -0.36157 -0.52164 -0.31883   \n",
      "2      10003 -1.71670  2.40120  0.44570  1.14400 -0.53560 -0.69040  0.39990   \n",
      "3      10004 -0.07260  0.31790 -1.38690  1.83000 -1.08930 -1.15900  0.05750   \n",
      "4      10005  0.32088 -1.08450 -1.15780 -0.63845  1.03060  0.38707  0.95113   \n",
      "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "62178  96207 -1.45150 -0.95600 -0.89920 -0.80340 -0.83730  2.07520 -2.71140   \n",
      "62179  96208  1.27570 -1.32360  2.00620 -1.61870 -0.72743  0.58177 -2.55890   \n",
      "62180  96209  0.35809 -2.22570  0.22366 -2.89240  0.43210 -1.64220 -0.12659   \n",
      "62181  96210  0.40804 -2.27950 -0.83962 -1.03440  1.04950  1.32130  1.27670   \n",
      "62182  96211 -0.74982  0.35505 -0.47464 -2.38330 -1.45550 -0.62356 -1.79640   \n",
      "\n",
      "            v8       v9  ...      v491     v492      v493      v494     v495  \\\n",
      "0     -0.69190 -0.99791  ...  0.038877 -0.81235  0.933330  0.534380  0.75724   \n",
      "1      1.06740  0.75016  ... -1.366200 -0.50756  0.014574  1.254400  1.47300   \n",
      "2      1.63330 -0.43470  ...  0.102600  2.38170  1.318500 -0.866900  0.97240   \n",
      "3      0.72450 -0.47780  ...  0.055500  0.48700  1.390100  1.404000 -2.53400   \n",
      "4      0.30132 -1.08750  ...  0.241960  1.93180 -0.930670  0.757390  0.65279   \n",
      "...        ...      ...  ...       ...      ...       ...       ...      ...   \n",
      "62178  1.63910  0.79040  ... -0.935500 -1.42240 -0.239600 -0.080800  0.35160   \n",
      "62179  0.46077 -2.32850  ... -0.523610  0.74670  0.517040 -0.189150  2.19590   \n",
      "62180 -0.65374 -4.12450  ...  1.970200  3.30630  2.595300 -0.936870 -0.88340   \n",
      "62181  0.71817  1.09210  ... -2.847900  0.23018 -0.046523 -0.976680  0.41813   \n",
      "62182 -2.61440 -0.72109  ... -0.410040  1.77290 -2.027400 -0.076067 -3.03920   \n",
      "\n",
      "          v496      v497     v498     v499         Error_Label  \n",
      "0     -1.03830 -0.758880  0.29875 -1.12810  000000000000000100  \n",
      "1      0.45056 -2.005600  1.19390 -2.21030  000000000000000000  \n",
      "2      0.87710 -1.038700  0.78180  0.56360  000000000000000000  \n",
      "3     -1.77610 -1.188000  1.13680 -0.11580  000000000000000000  \n",
      "4     -0.52051  0.406710  0.36767  1.08240  000000000001000000  \n",
      "...        ...       ...      ...      ...                 ...  \n",
      "62178  0.04230  0.039200 -0.14330 -1.16540  000001000011010000  \n",
      "62179 -0.38150  0.150240 -1.41880 -1.57960  010001000000001000  \n",
      "62180  0.23934 -1.231100 -0.55202 -0.23169  000001000000000000  \n",
      "62181 -0.31383 -1.897800 -0.23670 -0.44662  000001000011010000  \n",
      "62182 -1.61440 -0.097925 -1.14480 -0.12252  000001000011010000  \n",
      "\n",
      "[62183 rows x 501 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "data = pd.read_csv(r'/home/supriya/pathcontext/vectorization_work/CDS_vectorization_v1.csv',dtype={'Error_Label':object} )\n",
    "print(data)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62183, 501)\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "62178    0\n",
      "62179    0\n",
      "62180    0\n",
      "62181    0\n",
      "62182    0\n",
      "Name: l1, Length: 62183, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split labels and return new dataframe\n",
    "#Create independent and Dependent Features\n",
    "#data=split_label(data)\n",
    "def split_label_dict(df):\n",
    "    # Change 'label' to whatever naming used in the original DataFrame.\n",
    "    temp_df = df['Error_Label'].str.split(\"\", n = -1, expand = True)\n",
    "    for i in range(1, 19):\n",
    "        df[f'l{1}'] = temp_df[1]\n",
    "        df[f'l{1}'] = pd.to_numeric(df[f'l{1}'])\n",
    "    return df\n",
    "\n",
    "newdata=split_label_dict(data)\n",
    "#Create independent and Dependent Features\n",
    "columns = newdata.columns.tolist()\n",
    "# Filter the columns to remove data we do not want \n",
    "columns = [c for c in columns if c not in [\"l1\"]]\n",
    "# Store the variable we are predicting \n",
    "target = \"l1\"\n",
    "# Define a random state \n",
    "state = np.random.RandomState(69)\n",
    "X = newdata[columns]\n",
    "Y = newdata[target]\n",
    "# Print the shapes of X & Y\n",
    "print(X.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=69,stratify=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting Kernel SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
